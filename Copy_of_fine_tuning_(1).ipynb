{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YousefAli176/YousefAli176/blob/main/Copy_of_fine_tuning_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rN40tYPC8D96"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers\n",
        "import transformers\n",
        "from transformers import GPT2Tokenizer,GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "fZE10G1A_TBu",
        "outputId": "97c0b6e0-0d0c-4957-aa97-ea3598a2dca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "huggingface_hub"
                ]
              },
              "id": "655145ca51f64224b0904f472f5e2dd9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#!pip install datasets\n",
        "#!pip install accelerate -U\n",
        "#run one at each time and then restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOewXXpm8D98"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA2gB-SR8D98"
      },
      "outputs": [],
      "source": [
        "model_name=\"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model=GPT2LMHeadModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUCl4AzP8D99"
      },
      "outputs": [],
      "source": [
        "input_data=\" python can be very\"\n",
        "max_length=100\n",
        "num_return_sequences=1\n",
        "input_ids = tokenizer(input_data,return_tensors=\"pt\")[\"input_ids\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q79MSQov8D99",
        "outputId": "98219146-3d0c-4287-cefd-39e6c196f46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "output = model.generate(input_ids,\n",
        "                        max_length=max_length,\n",
        "                        num_return_sequences=num_return_sequences,  # Fixed parameter\n",
        "                        temperature=0.7,\n",
        "                        top_k=20,  # for more diverse sampling\n",
        "                        no_repeat_ngram_size=2\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVYgooaZ5Fh8"
      },
      "outputs": [],
      "source": [
        "#model.generate??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1UJrXPY8D99",
        "outputId": "025ed229-b900-4b94-9ea4-a3611953f08a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sequence before fine tuning  1:  python can be very useful for debugging.\n",
            "\n",
            "The following code snippet shows how to use the debugger to debug a program. It is a simple example of how the program can run in a debugger. The code is written in C++. You can see the code in the source code.<|endoftext|>\n",
            "\n",
            "End of sequence \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, sequence in enumerate(output):\n",
        "    print(f\"Generated sequence before fine tuning  {i + 1}: {tokenizer.decode(sequence)}\")\n",
        "    print(\"\\nEnd of sequence \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPrDeqqT8D99",
        "outputId": "4957ddec-90e8-473c-c1ca-ddff3bea52c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFLsocWwDRWO"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, TextDataset, DataCollatorForLanguageModeling, Trainer\n",
        "\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQgg69Cz8D9-"
      },
      "outputs": [],
      "source": [
        "#dataset = load_dataset('bookcorpus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVyYTg8g8D9-"
      },
      "outputs": [],
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXDfSmyZ8D9-"
      },
      "outputs": [],
      "source": [
        "#travel_keywords = r\"(?i)\\b(Python)\\b\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B61C0pbz8D9-"
      },
      "outputs": [],
      "source": [
        "#import re\n",
        "\n",
        "#filtered_dataset = dataset[\"train\"].filter(\n",
        " #   lambda x: re.compile(travel_keywords).search(x[\"text\"]) is not None\n",
        "#)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FIB3DSi8D9_"
      },
      "outputs": [],
      "source": [
        "#filtered_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iya934-8D9_"
      },
      "outputs": [],
      "source": [
        "#filtered_dataset.to_csv('travel.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1mgPn828D9_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataset is named \"my_dataset.csv\"\n",
        "travel_data = pd.read_csv(\"/content/sample_data/python.csv\")\n",
        "travel_data =travel_data[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDq1mYnj8D9_"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # Remove extra spaces\n",
        "    return text.lower()  # Convert to lowercase\n",
        "\n",
        "travel_data['text'] = travel_data['text'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iOdp1ed8D9_"
      },
      "outputs": [],
      "source": [
        "# Clean travel descriptions\n",
        "travel_data[\"cleaned_text\"] = travel_data[\"text\"].apply(clean_text)\n",
        "\n",
        "# Create Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(travel_data[[\"cleaned_text\"]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6ZoEbJiMAZf",
        "outputId": "94de1de4-25cf-4750-9714-3106618138c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "736\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqsfnt1V8D-A",
        "outputId": "0b5ecfa4-f626-4226-c11f-a279279af26b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'cleaned_text': 'an image popped into his head glowing just like the grailshaped beacon in that monty python moviea bottle of bourbon '}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1QcVsdW8D-A"
      },
      "outputs": [],
      "source": [
        "#with open(\"data.txt\", \"w\") as f:\n",
        "  #  for data in train_dataset[\"cleaned_text\"]:\n",
        "    #    f.write(\" \".join(map(str, data)) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaswJJ_I8D-A",
        "outputId": "d3ee2814-bda7-452a-a66f-4706e57eef1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"/content/sample_data/python.csv\",\n",
        "    block_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVUasCzhCbUE"
      },
      "outputs": [],
      "source": [
        "#!pip install accelerate -U\n",
        "#!pip install accelerate\n",
        "#!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfEcfrvS8D-A"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./output\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,  # Adjust number of epochs\n",
        "    per_device_train_batch_size=4,  # Adjust batch size based on GPU memory\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,  # Save only the two best checkpoints\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsOMMc3VJTKG"
      },
      "outputs": [],
      "source": [
        "def load_data_collator(tokenizer, mlm = False):\n",
        "    return DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=mlm,\n",
        "    )\n",
        "data_collator1=load_data_collator(tokenizer,False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "jHNWaAe78D-A",
        "outputId": "e0409143-88ad-44e2-cc17-1f14db5b73b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [180/180 28:45, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=180, training_loss=3.911082288953993, metrics={'train_runtime': 1743.4828, 'train_samples_per_second': 0.408, 'train_steps_per_second': 0.103, 'total_flos': 46444658688000.0, 'train_loss': 3.911082288953993, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Create the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator1,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyZNN8uHXemZ"
      },
      "outputs": [],
      "source": [
        "trainer.save_model()\n",
        "model2 = GPT2LMHeadModel.from_pretrained(\"/content/output\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = GPT2LMHeadModel.from_pretrained(\"/content/output\")"
      ],
      "metadata": {
        "id": "-x98uJi7B02w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model2??"
      ],
      "metadata": {
        "id": "ZBD7oE0Bb2ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8tUPYTH8D-B",
        "outputId": "b9b485c9-3402-4802-c0b5-2a3ec163ce23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "output2 = model2.generate(input_ids,\n",
        "                        max_length=max_length,\n",
        "                        num_return_sequences=num_return_sequences,  # Fixed parameter\n",
        "                        temperature=0.7,\n",
        "                        top_k=20,  # for more diverse sampling\n",
        "                        no_repeat_ngram_size=2\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F64Ov7Nu8D-B",
        "outputId": "de6b7347-4f01-48ca-b687-e11578aef8f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sequence after fine tuning 1:  python can be very powerful, and it can even be used to kill a python.\"\n",
            "\"the python is a very large python, weighing in at over 1,000 pounds.\" he continued, looking at the python.\n",
            "the black python was a large black snake, with a long tail, a thick body, thick skin, smooth skin and a smooth mouth. it was the most powerful python in the world.\" i asked, wondering if he could tell me more about the black and white python?\n",
            "\n",
            "End of sequence \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, sequence1 in enumerate(output2):\n",
        "    print(f\"Generated sequence after fine tuning {i + 1}: {tokenizer.decode(sequence1)}\")\n",
        "    print(\"\\nEnd of sequence \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n"
      ],
      "metadata": {
        "id": "4NmBBwBTg1wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output2 = model2.generate(input_ids,\n",
        "                        max_length=max_length,\n",
        "                        num_return_sequences=num_return_sequences,  # Fixed parameter\n",
        "                        temperature=0.7,\n",
        "                        top_k=20,  # for more diverse sampling\n",
        "                        no_repeat_ngram_size=2\n",
        "                        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyAC2AS0g1zv",
        "outputId": "19f1dc47-c9d0-4cec-8a02-45a659a0afdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLNV7TnEtOWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498cfe3a-41cc-49a4-def0-5d523e2126b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.14102564102564102, recall=0.55, fmeasure=0.22448979591836735), mid=Score(precision=0.14102564102564102, recall=0.55, fmeasure=0.22448979591836735), high=Score(precision=0.14102564102564102, recall=0.55, fmeasure=0.22448979591836735)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.07792207792207792, recall=0.3157894736842105, fmeasure=0.12499999999999999), mid=Score(precision=0.07792207792207792, recall=0.3157894736842105, fmeasure=0.12499999999999999), high=Score(precision=0.07792207792207792, recall=0.3157894736842105, fmeasure=0.12499999999999999)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.11538461538461539, recall=0.45, fmeasure=0.1836734693877551), mid=Score(precision=0.11538461538461539, recall=0.45, fmeasure=0.1836734693877551), high=Score(precision=0.11538461538461539, recall=0.45, fmeasure=0.1836734693877551)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.14102564102564102, recall=0.55, fmeasure=0.22448979591836735), mid=Score(precision=0.14102564102564102, recall=0.55, fmeasure=0.22448979591836735), high=Score(precision=0.14102564102564102, recall=0.55, fmeasure=0.22448979591836735))}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "prediction=[tokenizer.decode(sequence1)]\n",
        "reference=[\"an image popped into his head glowing just like the grailshaped beacon in that monty python moviea bottle of bourbon \"]\n",
        "\n",
        "rouge=load_metric(\"rouge\")\n",
        "\n",
        "rouge.compute(predictions=prediction,references=reference)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVGrtqtOiqdz",
        "outputId": "8e91f2a0-2c57-4d0d-b1d7-42c90134222d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.2)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=ca8349327db443cf7a0e611e2c05329a0bc0a83600c81710848af1edfca83669\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_Ozqb0UaBTxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-NGLNZOSAC4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4912236,
          "sourceId": 8273069,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}